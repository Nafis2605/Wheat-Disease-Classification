# -*- coding: utf-8 -*-
"""cnn_with_class_150.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UED8Y19OZ-igftlYhKfwpaHK-8uo3C7Z
"""

from google.colab import drive
drive.mount('/content/drive')

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchsummary import summary
from torch.utils.data import DataLoader, Dataset
from sklearn.utils.class_weight import compute_class_weight
import numpy as np
import matplotlib.pyplot as plt
import os
import pickle

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define the CvT model (same as before)
class CNN(nn.Module):
    def __init__(self, num_classes):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)
        self.bn1 = nn.BatchNorm2d(64)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)
        self.bn2 = nn.BatchNorm2d(128)
        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)
        self.bn3 = nn.BatchNorm2d(256)

        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(256, num_classes)

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = F.relu(self.bn2(self.conv2(x)))
        x = F.relu(self.bn3(self.conv3(x)))
        x = self.global_pool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        return x

# Custom dataset
class NumpyDataset(Dataset):
    def __init__(self, image_path, label_path):
        self.images = np.load(image_path)
        self.labels = np.load(label_path)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        image = torch.tensor(self.images[idx]).float() / 255.0
        image = image.permute(2, 0, 1)  # Convert to C, H, W
        label = torch.tensor(self.labels[idx]).long()
        return image, label

# Load datasets
def load_data(image_path, label_path, batch_size):
    dataset = NumpyDataset(image_path, label_path)
    return DataLoader(dataset, batch_size=batch_size, shuffle=True)

batch_size = 32
train_loader = load_data('/content/drive/MyDrive/dm project/new_class/train_images.npy', '/content/drive/MyDrive/dm project/new_class/train_labels.npy', batch_size)
val_loader = load_data('/content/drive/MyDrive/dm project/new_class/val_images.npy', '/content/drive/MyDrive/dm project/new_class/val_labels.npy', batch_size)

# Calculate class weights
labels = np.load('/content/drive/MyDrive/dm project/new_class/train_labels.npy')
class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)
class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)

# Model, optimizer, and loss function
model = CNN(num_classes=12).to(device)
summary(model, input_size=(3, 224, 224))
optimizer = optim.Adam(model.parameters(), lr=0.0001)
criterion = nn.CrossEntropyLoss(weight=class_weights)

# Early stopping setup
early_stopping_patience = 30
best_val_loss = float('inf')
patience_counter = 0

# Training and validation loops
train_losses, val_losses = [], []

import os

# Ensure the directory for saving models exists
os.makedirs('/content/drive/MyDrive/dm project/cnn', exist_ok=True)

def train_epoch(model, train_loader, criterion, optimizer, epoch, num_epochs):
    model.train()
    total_loss, total_correct, total_samples = 0, 0, 0
    for step, (images, labels) in enumerate(train_loader):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * images.size(0)
        _, preds = torch.max(outputs, 1)
        total_correct += (preds == labels).sum().item()
        total_samples += labels.size(0)

        # Print step details
        if (step + 1) % 150 == 0:
            print(f"Epoch [{epoch+1}/{num_epochs}], Step [{step+1}/{len(train_loader)}], "
                  f"Loss: {loss.item():.4f}")

    return total_loss / total_samples, total_correct / total_samples

def validate_epoch(model, val_loader, criterion):
    model.eval()
    total_loss, total_correct, total_samples = 0, 0, 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            total_loss += loss.item() * images.size(0)
            _, preds = torch.max(outputs, 1)
            total_correct += (preds == labels).sum().item()
            total_samples += labels.size(0)
    return total_loss / total_samples, total_correct / total_samples

# Training loop with early stopping
num_epochs = 150
early_stopping_patience = 30
best_val_loss = float('inf')
patience_counter = 0
train_losses, train_accs, val_losses, val_accs = [], [], [], []
for epoch in range(num_epochs):
    print(f"\nStarting Epoch {epoch+1}/{num_epochs}")
    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, epoch, num_epochs)
    val_loss, val_acc = validate_epoch(model, val_loader, criterion)

    train_losses.append(train_loss)
    train_accs.append(train_acc)
    val_losses.append(val_loss)
    val_accs.append(val_acc)

    print(f"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, "
          f"Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}")

    # Early stopping check
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        patience_counter = 0
        print(f"Validation loss improved. Saving model at epoch {epoch+1}.")
        torch.save(model.state_dict(), '/content/drive/MyDrive/dm project/cnn/cnn_wwc_best_model_150.pth')
    else:
        patience_counter += 1
        if patience_counter >= early_stopping_patience:
            print(f"Early stopping at epoch {epoch+1}")
            break


# Save training history
with open('/content/drive/MyDrive/dm project/cnn/cnn_wwc_training_history_150.pkl', 'wb') as f:
    pickle.dump({'train_loss': train_losses, 'train_acc': train_accs, 'val_loss': val_losses, 'val_acc': val_accs}, f)

# Plot training and validation losses and accuracies
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(train_losses, label="Training Loss")
plt.plot(val_losses, label="Validation Loss")
plt.title("Training and Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(train_accs, label="Training Accuracy")
plt.plot(val_accs, label="Validation Accuracy")
plt.title("Training and Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()

plt.tight_layout()
plt.savefig('/content/drive/MyDrive/dm project/cnn/cnn_wwc_loss_plot_150.png')
plt.show()

from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
import seaborn as sns
import torch
import numpy as np
import matplotlib.pyplot as plt
import os

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchsummary import summary
from torch.utils.data import DataLoader, Dataset
from sklearn.utils.class_weight import compute_class_weight
import numpy as np
import matplotlib.pyplot as plt
import os
import pickle

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define the CvT model (same as before)
class CNN(nn.Module):
    def __init__(self, num_classes):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)
        self.bn1 = nn.BatchNorm2d(64)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)
        self.bn2 = nn.BatchNorm2d(128)
        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)
        self.bn3 = nn.BatchNorm2d(256)

        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(256, num_classes)

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = F.relu(self.bn2(self.conv2(x)))
        x = F.relu(self.bn3(self.conv3(x)))
        x = self.global_pool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        return x

# Custom dataset
class NumpyDataset(Dataset):
    def __init__(self, image_path, label_path):
        self.images = np.load(image_path)
        self.labels = np.load(label_path)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        image = torch.tensor(self.images[idx]).float() / 255.0
        image = image.permute(2, 0, 1)  # Convert to C, H, W
        label = torch.tensor(self.labels[idx]).long()
        return image, label

# Load datasets
def load_data(image_path, label_path, batch_size):
    dataset = NumpyDataset(image_path, label_path)
    return DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Class names
class_names = [
    'Aphid', 'Black Rust', 'Brown Rust', 'Fusarium Head Blight', 'Healthy',
    'Leaf Blight', 'Mildew', 'Mite', 'Septoria', 'Smut', 'Stripe Rust', 'Yellow Dwarf'
]

# Load test data
test_loader = load_data(
    '/content/drive/MyDrive/dm project/new_class/test_images.npy',
    '/content/drive/MyDrive/dm project/new_class/test_labels.npy',
    batch_size=32  # Specify batch size
)


# Load the model and weights
model = CNN(num_classes=len(class_names)).to(device)
model.load_state_dict(torch.load('/content/drive/MyDrive/dm project/cnn/cnn_wwc_best_model_150.pth'))
model.eval()

# Predict and evaluate
y_true, y_pred, y_prob = [], [], []
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        probabilities = torch.softmax(outputs, dim=1)  # Get probabilities
        _, preds = torch.max(outputs, 1)

        y_true.extend(labels.cpu().numpy())
        y_pred.extend(preds.cpu().numpy())
        y_prob.extend(probabilities.cpu().numpy())

y_true = np.array(y_true)
y_pred = np.array(y_pred)
y_prob = np.array(y_prob)

# Classification Report
report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)
overall_metrics = {
    "Accuracy": report["accuracy"],
    "Precision": np.mean([v["precision"] for k, v in report.items() if k in class_names]),
    "Recall": np.mean([v["recall"] for k, v in report.items() if k in class_names]),
    "F1-Score": np.mean([v["f1-score"] for k, v in report.items() if k in class_names])
}
print("\n=== Overall Metrics ===")
for metric, value in overall_metrics.items():
    print(f"{metric}: {value:.4f}")

print("\n=== Per Class Metrics ===")
for class_name in class_names:
    print(f"\nClass: {class_name}")
    for metric, value in report[class_name].items():
        print(f"  {metric.capitalize()}: {value:.4f}")

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.savefig('/content/drive/MyDrive/dm project/cnn/cnn_wwc_con_mat_150.png')
plt.show()

# Normalized Confusion Matrix
cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(10, 8))
sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.title('Normalized Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.savefig('/content/drive/MyDrive/dm project/cnn/cnn_wwc_n_con_mat_150.png')
plt.show()

# ROC Curve
plt.figure(figsize=(12, 8))
for i, class_name in enumerate(class_names):
    fpr, tpr, _ = roc_curve(y_true == i, y_prob[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'{class_name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.title('ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.savefig('/content/drive/MyDrive/dm project/cnn/cnn_wwc_roc_curve_150.png')
plt.show()

# Calculate Specificity
specificity = []
for i in range(len(class_names)):
    tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])
    fp = cm[:, i].sum() - cm[i, i]
    specificity.append(tn / (tn + fp))

print("\n=== Specificity Per Class ===")
for class_name, spec in zip(class_names, specificity):
    print(f"{class_name}: {spec:.4f}")

print("\n=== Overall Metrics Including Specificity ===")
overall_metrics["Specificity"] = np.mean(specificity)
for metric, value in overall_metrics.items():
    print(f"{metric}: {value:.4f}")

from sklearn.metrics import classification_report
import pandas as pd


# Generate the classification report
report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)

# Convert the report dictionary to a Pandas DataFrame
report_df = pd.DataFrame(report).transpose()

# Format 'precision', 'recall', and 'f1-score' to 2 decimal places
for col in ['precision', 'recall', 'f1-score']:
    if col in report_df.columns:
        report_df[col] = report_df[col].apply(lambda x: round(x, 2))

# Ensure 'support' is displayed as an integer
if 'support' in report_df.columns:
    report_df['support'] = report_df['support'].astype(int)

# Print the classification report as a table
print("Classification Report:")
print(report_df)

import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
from torchvision import transforms
from torchvision.utils import make_grid
import numpy as np
from PIL import Image
import matplotlib.cm as cm

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchsummary import summary
from torch.utils.data import DataLoader, Dataset
from sklearn.utils.class_weight import compute_class_weight
import numpy as np
import matplotlib.pyplot as plt
import os
import pickle

class GradCAM:
    def __init__(self, model, feature_layer):
        self.model = model
        self.feature_layer = feature_layer
        self.model.eval()
        self.feature_gradients = []
        self.feature_maps = []
        self.hooks = []

        # Register hooks
        self.hooks.append(self.feature_layer.register_forward_hook(self.save_feature_maps))
        self.hooks.append(self.feature_layer.register_backward_hook(self.save_gradients))

    def save_feature_maps(self, module, input, output):
        self.feature_maps.append(output.detach())

    def save_gradients(self, module, grad_input, grad_output):
        self.feature_gradients.append(grad_output[0].detach())

    def __call__(self, x, index=None):
        # Forward pass
        output = self.model(x)
        if index is None:
            index = output.argmax(dim=1)

        # Zero gradients
        self.model.zero_grad()

        # Target for backprop
        one_hot_output = torch.zeros_like(output)
        one_hot_output[0, index] = 1

        # Backward pass
        output.backward(gradient=one_hot_output)

        # Get gradients and feature maps
        gradients = self.feature_gradients[-1]
        feature_maps = self.feature_maps[-1]
        weights = torch.mean(gradients, dim=(2, 3), keepdim=True)

        # Weighted combination
        grad_cam_map = torch.sum(weights * feature_maps, dim=1)[0]
        grad_cam_map = F.relu(grad_cam_map)

        # Normalize the Grad-CAM map
        grad_cam_map = grad_cam_map / grad_cam_map.max()

        self.feature_gradients.clear()
        self.feature_maps.clear()

        return grad_cam_map.cpu().numpy()

# Class names
class_names = [
    'Aphid', 'Black Rust', 'Brown Rust', 'Fusarium Head Blight', 'Healthy',
    'Leaf Blight', 'Mildew', 'Mite', 'Septoria', 'Smut', 'Stripe Rust', 'Yellow Dwarf'
]

# Function to safely load the model
def safe_load_model(path, model):
    checkpoint = torch.load(path, map_location=device)
    model.load_state_dict(checkpoint)
    return model

def visualize_cam(image_tensor, cam_output):

    # Convert the image tensor to a PIL image
    image_pil = transforms.ToPILImage()(image_tensor).convert("RGB")

    # Convert CAM output to a colormap
    heatmap = np.uint8(255 * cm.jet(cam_output)[:, :, :3])  # Only RGB channels
    heatmap = Image.fromarray(heatmap).resize(image_pil.size, Image.LANCZOS)

    # Blend original image and heatmap
    overlay_image = Image.blend(image_pil, heatmap, alpha=0.5)  # Adjust alpha as needed
    return overlay_image

model = CNN(num_classes=len(class_names)).to(device)
#last convolutional outputs before classification layers
feature_layer = model.conv3

# Initialize Grad-CAM
grad_cam = GradCAM(model, feature_layer)

# Load data and initialize the model
test_loader = load_data(
    '/content/drive/MyDrive/dm project/new_class/test_images.npy',
    '/content/drive/MyDrive/dm project/new_class/test_labels.npy',
    batch_size=32  # Specify batch size
)
safe_load_model('/content/drive/MyDrive/dm project/cnn/cnn_wwc_best_model_150.pth', model)

# Generate Grad-CAM and visualize
images, labels = next(iter(test_loader))
image_tensor = images[0:1].to(device)  # Process one image at a time

# Execute the model to get predictions
model.eval()
with torch.no_grad():
    outputs = model(image_tensor)
    _, predicted = torch.max(outputs, 1)

predicted_class_name = class_names[predicted.item()]
original_class_name = class_names[labels[0].item()]

# Generate Grad-CAM
cam_output = grad_cam(image_tensor)

# Visualization function to overlay heatmap
overlay_image = visualize_cam(images[0], cam_output)

# Display the images with class names
plt.figure(figsize=(15, 7))
plt.subplot(1, 2, 1)
plt.imshow(overlay_image)
plt.title(f'Predicted: {predicted_class_name}\nActual: {original_class_name}')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(transforms.ToPILImage()(images[0]))
plt.title('Original Image')
plt.axis('off')
plt.show()

import matplotlib.pyplot as plt
from torchvision import transforms

# Find examples of correct and incorrect predictions
correct_image = None
incorrect_image = None

for images, labels in test_loader:
    images, labels = images.to(device), labels.to(device)
    outputs = model(images)
    _, predicted = torch.max(outputs, 1)

    for i in range(len(labels)):
        if predicted[i] == labels[i] and correct_image is None:  # Find correct prediction
            correct_image = (images[i], labels[i], predicted[i])  # Save image, true label, and predicted label
        elif predicted[i] != labels[i] and incorrect_image is None:  # Find incorrect prediction
            incorrect_image = (images[i], labels[i], predicted[i])  # Save image, true label, and predicted label

        # Break the loop if both examples are found
        if correct_image and incorrect_image:
            break
    if correct_image and incorrect_image:
        break

# Check if examples were found
if not correct_image:
    print("No correctly classified example found.")
if not incorrect_image:
    print("No misclassified example found.")

# Visualization
plt.figure(figsize=(12, 12))

if correct_image:
    # Display the original image for the correct prediction
    plt.subplot(2, 2, 1)
    plt.imshow(transforms.ToPILImage()(correct_image[0].cpu()))
    plt.title(f'Original (Correct)\nActual: {class_names[correct_image[1].item()]}')
    plt.axis('off')

    # Display the CAM overlay for the correct prediction
    plt.subplot(2, 2, 2)
    cam_output = grad_cam(correct_image[0].unsqueeze(0))  # Generate CAM
    overlay_image = visualize_cam(correct_image[0].cpu(), cam_output)
    plt.imshow(overlay_image)
    plt.title(f'Grad-CAM (Correct)\nPredicted: {class_names[correct_image[2].item()]}')
    plt.axis('off')

if incorrect_image:
    # Display the original image for the incorrect prediction
    plt.subplot(2, 2, 3)
    plt.imshow(transforms.ToPILImage()(incorrect_image[0].cpu()))
    plt.title(f'Original (Incorrect)\nActual: {class_names[incorrect_image[1].item()]}')
    plt.axis('off')

    # Display the CAM overlay for the incorrect prediction
    plt.subplot(2, 2, 4)
    cam_output = grad_cam(incorrect_image[0].unsqueeze(0))  # Generate CAM
    overlay_image = visualize_cam(incorrect_image[0].cpu(), cam_output)
    plt.imshow(overlay_image)
    plt.title(f'Grad-CAM (Incorrect)\nPredicted: {class_names[incorrect_image[2].item()]}')
    plt.axis('off')

# Adjust subplot parameters to reduce space
plt.subplots_adjust(wspace=0.2, hspace=0.3)
plt.show()

import matplotlib.pyplot as plt
from torchvision import transforms

# Find an example of a correct prediction
correct_image = None

for images, labels in test_loader:
    images, labels = images.to(device), labels.to(device)
    outputs = model(images)
    _, predicted = torch.max(outputs, 1)

    for i in range(len(labels)):
        if predicted[i] == labels[i]:  # Check if the prediction is correct
            correct_image = (images[i], labels[i], predicted[i])  # Save image, true label, and predicted label
            break
    if correct_image:
        break

if not correct_image:
    print("No correctly classified example found.")
else:
    # Visualize the correct prediction
    plt.figure(figsize=(12, 6))

    # Display the original image for the correct prediction
    plt.subplot(1, 2, 1)  # Use 1 row and 2 columns for side-by-side comparison
    plt.imshow(transforms.ToPILImage()(correct_image[0].cpu()))
    plt.title(f'Original (Correct)\nActual: {class_names[correct_image[1].item()]}')
    plt.axis('off')

    # Display the CAM overlay for the correct prediction
    plt.subplot(1, 2, 2)
    cam_output = grad_cam(correct_image[0].unsqueeze(0))  # Generate CAM
    overlay_image = visualize_cam(correct_image[0].cpu(), cam_output)
    plt.imshow(overlay_image)
    plt.title(f'Grad-CAM (Correct)\nPredicted: {class_names[correct_image[2].item()]}')
    plt.axis('off')

    # Adjust subplot parameters to reduce horizontal space
    plt.subplots_adjust(wspace=0.05)

    plt.show()