# -*- coding: utf-8 -*-
"""gradcam.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iW36PjxJJC0OXij-dpgX0f2KtPOxQ6O2
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import models, transforms
from torchvision.utils import make_grid
from torchsummary import summary

import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import matplotlib.cm as cm

from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.preprocessing import label_binarize

from itertools import cycle
from datetime import datetime
import os
import pickle
import random

class CustomDataset(Dataset):
    def __init__(self, images, labels, transform=None):
        self.images = images
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        image = self.images[idx]
        label = self.labels[idx]
        if self.transform:
            image = self.transform(image)
        return image, label

# Define the model
class ResNetClassifier(nn.Module):
    def __init__(self, num_classes):
        super(ResNetClassifier, self).__init__()
        self.resnet = models.resnet50(pretrained=True)

        # Modify the first convolutional layer to accept 256 channels
        self.resnet.conv1 = nn.Conv2d(
            in_channels=3,  # Match input channel count
            out_channels=64,
            kernel_size=7,
            stride=2,
            padding=3,
            bias=False,
        )
        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)

    def forward(self, x):
        return self.resnet(x)

def load_checkpoint(checkpoint_path, model):
    print(f"Loading checkpoint from {checkpoint_path}...")
    checkpoint = torch.load(checkpoint_path)
    model.load_state_dict(checkpoint['model_state_dict'])
    start_epoch = checkpoint['epoch']
    val_loss = checkpoint.get('val_loss', None)
    val_accuracy = checkpoint.get('val_accuracy', None)
    print(f"Resumed from epoch {start_epoch}, val_loss: {val_loss:.4f}, val_accuracy: {val_accuracy:.2f}%")
    return model, start_epoch, val_loss


class GradCAM:
    def __init__(self, model, feature_layer):
        self.model = model
        self.feature_layer = feature_layer
        self.model.eval()
        self.feature_gradients = []
        self.feature_maps = []
        self.hooks = []

        # Register hooks
        self.hooks.append(self.feature_layer.register_forward_hook(self.save_feature_maps))
        self.hooks.append(self.feature_layer.register_backward_hook(self.save_gradients))

    def save_feature_maps(self, module, input, output):
        self.feature_maps.append(output.detach())

    def save_gradients(self, module, grad_input, grad_output):
        self.feature_gradients.append(grad_output[0].detach())

    def __call__(self, x, index=None):
        # Forward pass
        output = self.model(x)
        if index is None:
            index = output.argmax(dim=1)

        # Zero gradients
        self.model.zero_grad()

        # Target for backprop
        one_hot_output = torch.zeros_like(output)
        one_hot_output[0, index] = 1

        # Backward pass
        output.backward(gradient=one_hot_output)

        # Get gradients and feature maps
        gradients = self.feature_gradients[-1]
        feature_maps = self.feature_maps[-1]
        weights = torch.mean(gradients, dim=(2, 3), keepdim=True)

        # Weighted combination
        grad_cam_map = torch.sum(weights * feature_maps, dim=1)[0]
        grad_cam_map = F.relu(grad_cam_map)

        # Normalize the Grad-CAM map
        grad_cam_map = grad_cam_map / grad_cam_map.max()

        self.feature_gradients.clear()
        self.feature_maps.clear()

        return grad_cam_map.cpu().numpy()

def visualize_cam(image_tensor, cam_output):

    # Convert the image tensor to a PIL image
    image_pil = transforms.ToPILImage()(image_tensor).convert("RGB")

    # Convert CAM output to a colormap
    heatmap = np.uint8(255 * cm.jet(cam_output)[:, :, :3])  # Only RGB channels
    heatmap = Image.fromarray(heatmap).resize(image_pil.size, Image.LANCZOS)

    # Blend original image and heatmap
    overlay_image = Image.blend(image_pil, heatmap, alpha=0.5)  # Adjust alpha as needed
    return overlay_image

train_images = np.load('../dataset/train_images.npy')
train_labels = np.load('../dataset/train_labels.npy')
val_images = np.load('../dataset/val_images.npy')
val_labels = np.load('../dataset/val_labels.npy')
test_images = np.load('../dataset/test_images.npy')
test_labels = np.load('../dataset/test_labels.npy')

transform = transforms.Compose([
    transforms.ToTensor(),
    # transforms.Normalize(mean=[0.5], std=[0.5])  # Adjust mean/std for grayscale or RGB as needed
])

train_dataset = CustomDataset(train_images, train_labels, transform=transform)
val_dataset = CustomDataset(val_images, val_labels, transform=transform)
test_dataset = CustomDataset(test_images, test_labels, transform=transform)

batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

num_classes = len(np.unique(train_labels))

# Define device, including support for macOS MPS (Metal Performance Shaders)
if torch.backends.mps.is_available():
    device = torch.device("mps")
    print("Using macOS GPU (MPS)")
elif torch.cuda.is_available():
    device = torch.device("cuda")
    print("Using NVIDIA GPU")
else:
    device = torch.device("cpu")
    print("Using CPU")

model = ResNetClassifier(num_classes)
model = model.to(device)

class_names = [
    'Aphid', 'Black Rust', 'Brown Rust', 'Fusarium Head Blight', 'Healthy',
    'Leaf Blight', 'Mildew', 'Mite', 'Septoria', 'Smut', 'Stripe Rust', 'Yellow Dwarf']

# Assuming you want the last convolutional outputs before classification layers
feature_layer = model.resnet.layer4

# Initialize Grad-CAM
grad_cam = GradCAM(model, feature_layer)

# Function to randomly select one correct and one incorrect identification
def get_random_correct_incorrect(test_loader, model, device, class_names):
    correct_samples = []
    incorrect_samples = []
    model.eval()

    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)

            for img, pred, label in zip(images, predicted, labels):
                if pred == label:
                    correct_samples.append((img, pred, label))
                else:
                    incorrect_samples.append((img, pred, label))

    # Randomly choose one correct and one incorrect identification
    correct_sample = random.choice(correct_samples) if correct_samples else None
    incorrect_sample = random.choice(incorrect_samples) if incorrect_samples else None
    return correct_sample, incorrect_sample


def visualize_model_in_gradcam(test_loader, model, device, class_names):
    # Get a random correct and incorrect sample
    correct_sample, incorrect_sample = get_random_correct_incorrect(test_loader, model, device, class_names)

    # Check if we found at least one correct and one incorrect sample
    if correct_sample:
        correct_img, correct_pred, correct_label = correct_sample
        correct_pred_class = class_names[correct_pred.item()]
        correct_actual_class = class_names[correct_label.item()]

        # Generate Grad-CAM for correct sample
        cam_output_correct = grad_cam(correct_img.unsqueeze(0))
        overlay_image_correct = visualize_cam(correct_img.cpu(), cam_output_correct)

    if incorrect_sample:
        incorrect_img, incorrect_pred, incorrect_label = incorrect_sample
        incorrect_pred_class = class_names[incorrect_pred.item()]
        incorrect_actual_class = class_names[incorrect_label.item()]

        # Generate Grad-CAM for incorrect sample
        cam_output_incorrect = grad_cam(incorrect_img.unsqueeze(0))
        overlay_image_incorrect = visualize_cam(incorrect_img.cpu(), cam_output_incorrect)

    # Visualize results
    plt.figure(figsize=(15, 10))

    # Correct prediction visualization
    if correct_sample:
        plt.subplot(2, 2, 1)
        plt.imshow(overlay_image_correct)
        plt.title(f'Correct Prediction:\nPredicted: {correct_pred_class}\nActual: {correct_actual_class}')
        plt.axis('off')

        plt.subplot(2, 2, 2)
        plt.imshow(transforms.ToPILImage()(correct_img.cpu()))
        plt.title('Original Image (Correct)')
        plt.axis('off')

    # Incorrect prediction visualization
    if incorrect_sample:
        plt.subplot(2, 2, 3)
        plt.imshow(overlay_image_incorrect)
        plt.title(f'Incorrect Prediction:\nPredicted: {incorrect_pred_class}\nActual: {incorrect_actual_class}')
        plt.axis('off')

        plt.subplot(2, 2, 4)
        plt.imshow(transforms.ToPILImage()(incorrect_img.cpu()))
        plt.title('Original Image (Incorrect)')
        plt.axis('off')

    plt.tight_layout()
    plt.show()

checkpoint_dir = "../models/checkpoints_cross_op0001/"
checkpoint_path = os.path.join(checkpoint_dir, "best_model.pth")
model, start_epoch, val_loss = load_checkpoint(checkpoint_path, model)

# Generate Grad-CAM and visualize
images, labels = next(iter(test_loader))
image_tensor = images[0:1].to(device)  # Process one image at a time

# Execute the model to get predictions
model.eval()
with torch.no_grad():
    outputs = model(image_tensor)
    _, predicted = torch.max(outputs, 1)

predicted_class_name = class_names[predicted.item()]
original_class_name = class_names[labels[0].item()]

# Generate Grad-CAM
cam_output = grad_cam(image_tensor)

# Visualization function to overlay heatmap
overlay_image = visualize_cam(images[0], cam_output)

# Display the images with class names
plt.figure(figsize=(15, 7))
plt.subplot(1, 2, 1)
plt.imshow(overlay_image)
plt.title(f'Predicted: {predicted_class_name}\nActual: {original_class_name}')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(transforms.ToPILImage()(images[0]))
plt.title('Original Image')
plt.axis('off')
plt.show()

