# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xOyMrS8Cd1DWPWdtW2iHROj4CQo7YzXa
"""

from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
from itertools import cycle
import os
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import models, transforms
from sklearn.utils.class_weight import compute_class_weight
from datetime import datetime
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

class CustomDataset(Dataset):
    def __init__(self, images, labels, transform=None):
        self.images = images
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        image = self.images[idx]
        label = self.labels[idx]
        if self.transform:
            image = self.transform(image)
        return image, label

# Define the model
class ResNetClassifier(nn.Module):
    def __init__(self, num_classes):
        super(ResNetClassifier, self).__init__()
        self.resnet = models.resnet50(pretrained=True)

        # Modify the first convolutional layer to accept 256 channels
        self.resnet.conv1 = nn.Conv2d(
            in_channels=3,  # Match input channel count
            out_channels=64,
            kernel_size=7,
            stride=2,
            padding=3,
            bias=False,
        )
        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)

    def forward(self, x):
        return self.resnet(x)

def load_checkpoint(checkpoint_path, model):
    print(f"Loading checkpoint from {checkpoint_path}...")
    checkpoint = torch.load(checkpoint_path)
    model.load_state_dict(checkpoint['model_state_dict'])
    start_epoch = checkpoint['epoch']
    val_loss = checkpoint.get('val_loss', None)
    val_accuracy = checkpoint.get('val_accuracy', None)
    print(f"Resumed from epoch {start_epoch}, val_loss: {val_loss:.4f}, val_accuracy: {val_accuracy:.2f}%")
    return model, start_epoch, val_loss

# Evaluate the model
def test(model, test_loader, device, class_names):
    model.eval()
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    report = classification_report(all_labels, all_preds, target_names=class_names)
    print("Classification Report:")
    print(report)


def generate_confusion_matrix(model, test_loader, device, class_names):
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # Compute confusion matrix
    cm = confusion_matrix(all_labels, all_preds, labels=range(len(class_names)))
    print("Confusion Matrix:\n", cm)

    true_positives = np.diag(cm)
    false_positives = cm.sum(axis=0) - true_positives
    false_negatives = cm.sum(axis=1) - true_positives
    true_negatives = cm.sum() - (false_positives + false_negatives + true_positives)
    with np.errstate(divide='ignore', invalid='ignore'):
        accuracy = (true_positives.sum() / cm.sum()) * 100
        precision = np.nan_to_num(true_positives / (true_positives + false_positives))
        sensitivity = np.nan_to_num(true_positives / (true_positives + false_negatives))  # Sensitivity (Recall)
        specificity = np.nan_to_num(true_negatives / (true_negatives + false_positives))

    overall_precision = np.mean(precision)
    overall_sensitivity = np.mean(sensitivity)
    overall_specificity = np.mean(specificity)

    # Print metrics
    print(f"Accuracy: {accuracy:.2f}%")
    print("Precision (per class):", precision)
    print("Sensitivity/Recall (per class):", sensitivity)
    print("Specificity (per class):", specificity)
    print(f"Overall Precision: {overall_precision:.2f}")
    print(f"Overall Sensitivity (Recall): {overall_sensitivity:.2f}")
    print(f"Overall Specificity: {overall_specificity:.2f}")


    # Display confusion matrix with rotated labels
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    fig, ax = plt.subplots(figsize=(10, 8))  # Create a new figure with custom size
    disp.plot(cmap=plt.cm.Blues, ax=ax)      # Use the custom figure's axes

    # Rotate the x-axis labels
    ax.set_xticklabels(class_names, rotation=90)

    # Add title and display
    plt.title("Confusion Matrix")
    plt.tight_layout()  # Adjust layout to prevent clipping
    plt.show()


    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

     # Display confusion matrix with rotated labels
    disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=class_names)
    fig, ax = plt.subplots(figsize=(10, 8))  # Create a new figure with custom size
    disp.plot(cmap=plt.cm.Blues, ax=ax)      # Use the custom figure's axes

    # Rotate the x-axis labels
    ax.set_xticklabels(class_names, rotation=90)

    # Add title and display
    plt.title("Normalized Confusion Matrix")
    plt.tight_layout()  # Adjust layout to prevent clipping
    plt.show()



def plot_roc_curves(model, test_loader, device, class_names):
    # Get the number of classes
    n_classes = len(class_names)

    # Collect all predictions and true labels
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            all_preds.append(outputs.cpu().numpy())
            all_labels.append(labels.cpu().numpy())

    # Convert lists to numpy arrays
    all_preds = np.concatenate(all_preds, axis=0)
    all_labels = np.concatenate(all_labels, axis=0)

    # Binarize the labels for ROC computation
    all_labels = label_binarize(all_labels, classes=range(n_classes))

    # Compute ROC curve and ROC area for each class
    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    for i in range(n_classes):
        fpr[i], tpr[i], _ = roc_curve(all_labels[:, i], all_preds[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    # Compute micro-average ROC curve and ROC area
    fpr["micro"], tpr["micro"], _ = roc_curve(all_labels.ravel(), all_preds.ravel())
    roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

    # Plot ROC curves
    plt.figure(figsize=(12, 9.6))
    colors = cycle(["aqua", "darkorange", "cornflowerblue", "darkred", "green"])
    for i, color in zip(range(n_classes), colors):
        plt.plot(fpr[i], tpr[i], color=color, lw=2,
                 label=f"ROC curve for class {class_names[i]} (area = {roc_auc[i]:.2f})")

    plt.plot(fpr["micro"], tpr["micro"], color="deeppink", linestyle="--", lw=2,
             label=f"micro-average ROC curve (area = {roc_auc['micro']:.2f})")

    plt.plot([0, 1], [0, 1], "k--", lw=2)
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("Receiver Operating Characteristic (ROC)")
    plt.legend(loc="lower right")
    plt.show()

# Example: Call the function to plot ROC curves

train_images = np.load('../dataset/train_images.npy')
train_labels = np.load('../dataset/train_labels.npy')
val_images = np.load('../dataset/val_images.npy')
val_labels = np.load('../dataset/val_labels.npy')
test_images = np.load('../dataset/test_images.npy')
test_labels = np.load('../dataset/test_labels.npy')

transform = transforms.Compose([
    transforms.ToTensor(),
    # transforms.Normalize(mean=[0.5], std=[0.5])  # Adjust mean/std for grayscale or RGB as needed
])

train_dataset = CustomDataset(train_images, train_labels, transform=transform)
val_dataset = CustomDataset(val_images, val_labels, transform=transform)
test_dataset = CustomDataset(test_images, test_labels, transform=transform)

batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

num_classes = len(np.unique(train_labels))

# Define device, including support for macOS MPS (Metal Performance Shaders)
if torch.backends.mps.is_available():
    device = torch.device("mps")
    print("Using macOS GPU (MPS)")
elif torch.cuda.is_available():
    device = torch.device("cuda")
    print("Using NVIDIA GPU")
else:
    device = torch.device("cpu")
    print("Using CPU")

model = ResNetClassifier(num_classes)
model = model.to(device)

def generate_models_genjam(checkpoint_dir, model, test_loader, device):
    checkpoint_path = os.path.join(checkpoint_dir, "best_model.pth")
    model, start_epoch, val_loss = load_checkpoint(checkpoint_path, model)

    class_names = [
    'Aphid', 'Black Rust', 'Brown Rust', 'Fusarium Head Blight', 'Healthy',
    'Leaf Blight', 'Mildew', 'Mite', 'Septoria', 'Smut', 'Stripe Rust', 'Yellow Dwarf']

    test(model, test_loader, device, class_names)
    generate_confusion_matrix(model, test_loader, device, class_names)

    plot_roc_curves(model, test_loader, device, class_names)

checkpoint_dir = "../models/checkpoints_cross_op0001_noclass"
generate_models_genjam(checkpoint_dir, model, test_loader, device)

checkpoint_dir = "../models/checkpoints_cross_op0001"
generate_models_genjam(checkpoint_dir, model, test_loader, device)

checkpoint_dir = "../models/checkpoints_focal_loss_op0001_noclass"
generate_models_genjam(checkpoint_dir, model, test_loader, device)