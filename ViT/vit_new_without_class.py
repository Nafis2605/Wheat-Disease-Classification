# -*- coding: utf-8 -*-
"""vit_new_without_class.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19EMafNPm3x64o_daJMb14DCGK0n15vBX
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchinfo import summary
from sklearn.utils.class_weight import compute_class_weight
import numpy as np
import matplotlib.pyplot as plt
import os
import pickle
import timm

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define the dataset class
class NumpyDataset(Dataset):
    def __init__(self, image_path, label_path):
        self.images = np.load(image_path)
        self.labels = np.load(label_path)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        image = torch.tensor(self.images[idx]).float() / 255.0
        image = image.permute(2, 0, 1)  # Convert to C, H, W
        label = torch.tensor(self.labels[idx]).long()
        return image, label

# Function to load data
def load_data(image_path, label_path, batch_size):
    dataset = NumpyDataset(image_path, label_path)
    return DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Initialize data loaders
batch_size = 32
train_loader = load_data('/home/sshultan/dm_project/new/train_images.npy', '/home/sshultan/dm_project/new/train_labels.npy', batch_size)
val_loader = load_data('/home/sshultan/dm_project/new/val_images.npy', '/home/sshultan/dm_project/new/val_labels.npy', batch_size)

# Load a pre-trained Vision Transformer model from timm
model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=12)
model.to(device)
summary(model, input_size=(1, 3, 224, 224), device=str(device))

# # Calculate class weights
# labels = np.load('/home/sshultan/dm_project/new/train_labels.npy')
# class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)
# class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)

# Setup optimizer and loss function
optimizer = optim.Adam(model.parameters(), lr=0.0001)
criterion = nn.CrossEntropyLoss()

# Early stopping setup
early_stopping_patience = 30
best_val_loss = float('inf')
patience_counter = 0

# Training and validation functions
def train_epoch(model, train_loader, criterion, optimizer, epoch, num_epochs):
    model.train()
    total_loss, total_correct, total_samples = 0, 0, 0
    for step, (images, labels) in enumerate(train_loader):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * images.size(0)
        _, preds = torch.max(outputs, 1)
        total_correct += (preds == labels).sum().item()
        total_samples += labels.size(0)

        if (step + 1) % 100 == 0:
            print(f"Epoch [{epoch+1}/{num_epochs}], Step [{step+1}/{len(train_loader)}], Loss: {loss.item():.4f}")

    return total_loss / total_samples, total_correct / total_samples

def validate_epoch(model, val_loader, criterion):
    model.eval()
    total_loss, total_correct, total_samples = 0, 0, 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            total_loss += loss.item() * images.size(0)
            _, preds = torch.max(outputs, 1)
            total_correct += (preds == labels).sum().item()
            total_samples += labels.size(0)
    return total_loss / total_samples, total_correct / total_samples

# Training loop
num_epochs = 150
train_losses, train_accs, val_losses, val_accs = [], [], [], []
for epoch in range(num_epochs):
    print(f"\nStarting Epoch {epoch+1}/{num_epochs}")
    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, epoch, num_epochs)
    val_loss, val_acc = validate_epoch(model, val_loader, criterion)

    train_losses.append(train_loss)
    train_accs.append(train_acc)
    val_losses.append(val_loss)
    val_accs.append(val_acc)

    print(f"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}")

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        patience_counter = 0
        print(f"Validation loss improved. Saving model at epoch {epoch+1}.")
        torch.save(model.state_dict(), '/home/sshultan/dm_project/new/nvit/vit_best_model.pth')
    else:
        patience_counter += 1
        if patience_counter >= early_stopping_patience:
            print(f"Early stopping at epoch {epoch+1}")
            break

# Save training history
with open('/home/sshultan/dm_project/new/nvit/vit_training_history.pkl', 'wb') as f:
    pickle.dump({'train_loss': train_losses, 'train_acc': train_accs, 'val_loss': val_losses, 'val_acc': val_accs}, f)

# Plot training and validation losses and accuracies
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(train_losses, label="Training Loss")
plt.plot(val_losses, label="Validation Loss")
plt.title("Training and Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(train_accs, label="Training Accuracy")
plt.plot(val_accs, label="Validation Accuracy")
plt.title("Training and Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()

plt.tight_layout()
plt.savefig('/home/sshultan/dm_project/new/nvit/vit_loss_acc_plot.png')
plt.show()

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
import timm

# Set the device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Custom dataset class
class NumpyDataset(Dataset):
    def __init__(self, image_path, label_path):
        self.images = np.load(image_path)
        self.labels = np.load(label_path)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        image = torch.tensor(self.images[idx]).float() / 255.0
        image = image.permute(2, 0, 1)  # Convert to C, H, W
        label = torch.tensor(self.labels[idx]).long()
        return image, label

# Function to load data
def load_data(image_path, label_path, batch_size):
    dataset = NumpyDataset(image_path, label_path)
    return DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Load test data
test_loader = load_data(
    '/home/sshultan/dm_project/new/test_images.npy',
    '/home/sshultan/dm_project/new/test_labels.npy',
    batch_size=32  # Specify batch size
)

# Class names
class_names = [
    'Aphid', 'Black Rust', 'Brown Rust', 'Fusarium Head Blight', 'Healthy',
    'Leaf Blight', 'Mildew', 'Mite', 'Septoria', 'Smut', 'Stripe Rust', 'Yellow Dwarf'
]

# Load the model
model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=12)
model.load_state_dict(torch.load('/home/sshultan/dm_project/new/nvit/vit_best_model.pth', map_location=device))
model.to(device)
model.eval()


y_true, y_pred, y_prob = [], [], []
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        probabilities = torch.softmax(outputs, dim=1)
        _, preds = torch.max(outputs, 1)

        y_true.extend(labels.cpu().numpy())
        y_pred.extend(preds.cpu().numpy())
        y_prob.append(probabilities.cpu().numpy())  # Change from extend to append


# Ensure y_true is a numpy array
y_true = np.array(y_true)

# Convert probabilities list to a numpy array if it's not already
y_prob = np.vstack(y_prob) if isinstance(y_prob, list) else np.array(y_prob)



# Classification Report
report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)
overall_metrics = {
    "Accuracy": report["accuracy"],
    "Precision": np.mean([v["precision"] for k, v in report.items() if k in class_names]),
    "Recall": np.mean([v["recall"] for k, v in report.items() if k in class_names]),
    "F1-Score": np.mean([v["f1-score"] for k, v in report.items() if k in class_names])
}
print("\n=== Overall Metrics ===")
for metric, value in overall_metrics.items():
    print(f"{metric}: {value:.4f}")

print("\n=== Per Class Metrics ===")
for class_name in class_names:
    print(f"\nClass: {class_name}")
    for metric, value in report[class_name].items():
        print(f"  {metric.capitalize()}: {value:.4f}")

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.savefig('/home/sshultan/dm_project/new/nvit/vit_cm_150.png')
plt.show()

# Normalized Confusion Matrix
cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(10, 8))
sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.title('Normalized Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.savefig('/home/sshultan/dm_project/new/nvit/vit_ncm_150.png')
plt.show()

# ROC Curve
plt.figure(figsize=(12, 8))
for i, class_name in enumerate(class_names):
    fpr, tpr, _ = roc_curve(y_true == i, y_prob[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'{class_name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.title('ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.savefig('/home/sshultan/dm_project/new/nvit/vit_roc_curve_150.png')
plt.show()

# Calculate Specificity
specificity = []
for i in range(len(class_names)):
    tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])
    fp = cm[:, i].sum() - cm[i, i]
    specificity.append(tn / (tn + fp))

print("\n=== Specificity Per Class ===")
for class_name, spec in zip(class_names, specificity):
    print(f"{class_name}: {spec:.4f}")

print("\n=== Overall Metrics Including Specificity ===")
overall_metrics["Specificity"] = np.mean(specificity)
for metric, value in overall_metrics.items():
    print(f"{metric}: {value:.4f}")




# Generate the classification report
report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)

# Convert the report dictionary to a Pandas DataFrame
report_df = pd.DataFrame(report).transpose()

# Format 'precision', 'recall', and 'f1-score' to 2 decimal places
for col in ['precision', 'recall', 'f1-score']:
    if col in report_df.columns:
        report_df[col] = report_df[col].apply(lambda x: round(x, 2))

# Ensure 'support' is displayed as an integer
if 'support' in report_df.columns:
    report_df['support'] = report_df['support'].astype(int)

# Print the classification report as a table
print("\n")
print("\n")
print("Classification Report:")
print(report_df)

import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
from torchvision import transforms
import numpy as np
from PIL import Image
import matplotlib.cm as cm
import timm
from torch.utils.data import DataLoader, Dataset

# Class names
class_names = [
    'Aphid', 'Black Rust', 'Brown Rust', 'Fusarium Head Blight', 'Healthy',
    'Leaf Blight', 'Mildew', 'Mite', 'Septoria', 'Smut', 'Stripe Rust', 'Yellow Dwarf'
]

# Custom Grad-CAM class
class GradCAM:
    def __init__(self, model, feature_layer):
        self.model = model
        self.feature_layer = feature_layer
        self.model.eval()
        self.feature_gradients = []
        self.feature_maps = []
        self.hooks = []

        # Register hooks
        self.hooks.append(self.feature_layer.register_forward_hook(self.save_feature_maps))
        self.hooks.append(self.feature_layer.register_full_backward_hook(self.save_gradients))

    def save_feature_maps(self, module, input, output):
        self.feature_maps.append(output.detach())

    def save_gradients(self, module, grad_input, grad_output):
        self.feature_gradients.append(grad_output[0].detach())

    def __call__(self, x, index=None):
        # Forward pass
        output = self.model(x)
        if index is None:
            index = output.argmax(dim=1)

        # Zero gradients
        self.model.zero_grad()

        # Target for backprop
        one_hot_output = torch.zeros_like(output)
        one_hot_output[0, index] = 1

        # Backward pass
        output.backward(gradient=one_hot_output)

        # Get gradients and feature maps
        gradients = self.feature_gradients[-1]  # Shape: [N, L, D]
        feature_maps = self.feature_maps[-1]  # Shape: [N, L, D]

        # Compute weights
        weights = torch.mean(gradients, dim=1, keepdim=True)  # Mean over sequence length

        # Weighted combination
        grad_cam_map = torch.sum(weights * feature_maps, dim=-1)  # Sum over embedding dimension (D)
        grad_cam_map = F.relu(grad_cam_map)  # Shape: [N, L]

        # Reshape to 2D grid (14x14 for ViT with 196 patches)
        patch_dim = int((grad_cam_map.size(1) - 1) ** 0.5)  # Exclude CLS token
        grad_cam_map = grad_cam_map[:, 1:].reshape(patch_dim, patch_dim).cpu().numpy()  # Exclude CLS token

        # Normalize CAM
        grad_cam_map = (grad_cam_map - grad_cam_map.min())
        if grad_cam_map.max() > 0:
            grad_cam_map /= grad_cam_map.max()

        self.feature_gradients.clear()
        self.feature_maps.clear()

        return grad_cam_map


# Visualization function
def visualize_cam(image_tensor, cam_output):
    # Convert tensor to PIL image
    image_pil = transforms.ToPILImage()(image_tensor).convert("RGB")

    # Create heatmap from CAM output
    heatmap = np.uint8(255 * cm.jet(cam_output)[:, :, :3])  # Only RGB channels
    heatmap = Image.fromarray(heatmap).resize(image_pil.size, Image.LANCZOS)

    # Blend original image and heatmap
    overlay_image = Image.blend(image_pil, heatmap, alpha=0.5)
    return overlay_image

# Dataset class
class NumpyDataset(Dataset):
    def __init__(self, image_path, label_path):
        self.images = np.load(image_path)
        self.labels = np.load(label_path)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        image = torch.tensor(self.images[idx]).float() / 255.0
        image = image.permute(2, 0, 1)  # Convert to C, H, W
        label = torch.tensor(self.labels[idx]).long()
        return image, label

# DataLoader
def load_data(image_path, label_path, batch_size):
    dataset = NumpyDataset(image_path, label_path)
    return DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Load model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=len(class_names))
model.load_state_dict(torch.load('/home/sshultan/dm_project/new/nvit/vit_best_model.pth', map_location=device))
model.to(device)
model.eval()

# Select feature layer
feature_layer = model.blocks[-1].norm1  # ViT-specific layer selection
grad_cam = GradCAM(model, feature_layer)

# Load test data
test_loader = load_data(
    '/home/sshultan/dm_project/new/test_images.npy',
    '/home/sshultan/dm_project/new/test_labels.npy',
    batch_size=32
)

# Process one image
images, labels = next(iter(test_loader))
images, labels = images.to(device), labels.to(device)
image_tensor = images[0]  # First image in the batch
true_label = labels[0].item()

# Get model prediction
with torch.no_grad():
    outputs = model(image_tensor.unsqueeze(0))  # Unsqueeze for batch dimension
    predicted_label = outputs.argmax(dim=1).item()

# Generate Grad-CAM
cam_output = grad_cam(image_tensor.unsqueeze(0))

# Resize Grad-CAM to match input image dimensions
cam_output_resized = np.kron(cam_output, np.ones((16, 16)))  # Adjust for ViT patch size

# Visualize the original image and Grad-CAM overlay
overlay_image = visualize_cam(image_tensor.cpu(), cam_output_resized)

# Display images
plt.figure(figsize=(12, 6))

# Original image
plt.subplot(1, 2, 1)
plt.imshow(transforms.ToPILImage()(image_tensor.cpu()))
plt.title(f'Original Image\nActual: {class_names[true_label]}')
plt.axis('off')

# Grad-CAM overlay
plt.subplot(1, 2, 2)
plt.imshow(overlay_image)
plt.title(f'Grad-CAM Overlay\nPredicted: {class_names[predicted_label]}')
plt.axis('off')

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
from torchvision import transforms
import torch

# Find examples of correct and incorrect predictions
correct_image = None
incorrect_image = None

for images, labels in test_loader:
    images, labels = images.to(device), labels.to(device)
    outputs = model(images)
    _, predicted = torch.max(outputs, 1)

    for i in range(len(labels)):
        if predicted[i] == labels[i] and correct_image is None:  # Find correct prediction
            correct_image = (images[i], labels[i].item(), predicted[i].item())  # Save image, true label, and predicted label
        elif predicted[i] != labels[i] and incorrect_image is None:  # Find incorrect prediction
            incorrect_image = (images[i], labels[i].item(), predicted[i].item())  # Save image, true label, and predicted label

        # Break the loop if both examples are found
        if correct_image and incorrect_image:
            break
    if correct_image and incorrect_image:
        break

# Check if examples were found
if not correct_image:
    print("No correctly classified example found.")
if not incorrect_image:
    print("No misclassified example found.")

# Visualization
plt.figure(figsize=(12, 12))

if correct_image:
    # Display the original image for the correct prediction
    plt.subplot(2, 2, 1)
    plt.imshow(transforms.ToPILImage()(correct_image[0].cpu()))
    plt.title(f'Original (Correct)\nActual: {class_names[correct_image[1]]}')
    plt.axis('off')

    # Display the CAM overlay for the correct prediction
    plt.subplot(2, 2, 2)
    cam_output = grad_cam(correct_image[0].unsqueeze(0))  # Generate CAM
    cam_output_resized = np.kron(cam_output, np.ones((16, 16)))  # Adjust for ViT patch size
    overlay_image = visualize_cam(correct_image[0].cpu(), cam_output_resized)
    plt.imshow(overlay_image)
    plt.title(f'Grad-CAM (Correct)\nPredicted: {class_names[correct_image[2]]}')
    plt.axis('off')

if incorrect_image:
    # Display the original image for the incorrect prediction
    plt.subplot(2, 2, 3)
    plt.imshow(transforms.ToPILImage()(incorrect_image[0].cpu()))
    plt.title(f'Original (Incorrect)\nActual: {class_names[incorrect_image[1]]}')
    plt.axis('off')

    # Display the CAM overlay for the incorrect prediction
    plt.subplot(2, 2, 4)
    cam_output = grad_cam(incorrect_image[0].unsqueeze(0))  # Generate CAM
    cam_output_resized = np.kron(cam_output, np.ones((16, 16)))  # Adjust for ViT patch size
    overlay_image = visualize_cam(incorrect_image[0].cpu(), cam_output_resized)
    plt.imshow(overlay_image)
    plt.title(f'Grad-CAM (Incorrect)\nPredicted: {class_names[incorrect_image[2]]}')
    plt.axis('off')

# Adjust subplot parameters to reduce space
plt.subplots_adjust(wspace=0.2, hspace=0.3)
plt.show()

import torch
import timm
from torchviz import make_dot
from torchinfo import summary

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Model setup
model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=12)
model.to(device)


# Get model summary
print(summary(model, input_size=(1, 3, 224, 224), device=str(device)))

